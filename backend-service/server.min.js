const express=require("express"),cors=require("cors"),multer=require("multer"),admin=require("firebase-admin"),{Octokit:Octokit}=require("@octokit/rest"),{createAppAuth:createAppAuth}=require("@octokit/auth-app"),fs=require("fs"),path=require("path"),sanitizeFilename=require("sanitize-filename"),crypto=require("crypto"),rateLimit=require("express-rate-limit"),{NUM_CHUNKS:NUM_CHUNKS}=require("./config.js"),PORT=process.env.PORT||1111,GITHUB_OWNER=process.env.GITHUB_OWNER,GITHUB_REPO=process.env.GITHUB_REPO,FIREBASE_SERVICE_ACCOUNT_PATH=process.env.FIREBASE_SERVICE_ACCOUNT_PATH,FIREBASE_PROJECT_ID=process.env.FIREBASE_PROJECT_ID,FRONTEND_ORIGIN=process.env.FRONTEND_ORIGIN,GITHUB_APP_ID=process.env.GITHUB_APP_ID,GITHUB_APP_PRIVATE_KEY=process.env.GITHUB_APP_PRIVATE_KEY,GITHUB_APP_PRIVATE_KEY_PATH=process.env.GITHUB_APP_PRIVATE_KEY_PATH,GITHUB_APP_INSTALLATION_ID=process.env.GITHUB_APP_INSTALLATION_ID,SERVER_TEMP_DIR=path.join(__dirname,"server_temp_uploads");function getGitHubAppPrivateKey(){if(GITHUB_APP_PRIVATE_KEY_PATH)try{return fs.readFileSync(GITHUB_APP_PRIVATE_KEY_PATH,"utf8")}catch(error){console.warn(`WARN: GITHUB_APP_PRIVATE_KEY_PATH is set but could not read file (${GITHUB_APP_PRIVATE_KEY_PATH}):`,error.message),console.warn("Falling back to GITHUB_APP_PRIVATE_KEY environment variable.")}if(GITHUB_APP_PRIVATE_KEY)return GITHUB_APP_PRIVATE_KEY;throw new Error("Missing GitHub App private key. Set GITHUB_APP_PRIVATE_KEY_PATH or GITHUB_APP_PRIVATE_KEY.")}const effectiveGitHubAppPrivateKey=getGitHubAppPrivateKey();GITHUB_OWNER&&GITHUB_REPO&&FIREBASE_SERVICE_ACCOUNT_PATH&&FIREBASE_PROJECT_ID&&FRONTEND_ORIGIN&&GITHUB_APP_ID&&effectiveGitHubAppPrivateKey&&GITHUB_APP_INSTALLATION_ID||(console.error("FATAL ERROR: Missing one or more required environment variables."),console.error(!GITHUB_OWNER,!GITHUB_REPO,!FIREBASE_SERVICE_ACCOUNT_PATH,!FIREBASE_PROJECT_ID,!FRONTEND_ORIGIN,!GITHUB_APP_ID,!effectiveGitHubAppPrivateKey,!GITHUB_APP_INSTALLATION_ID),process.exit(1));try{const serviceAccount=require(FIREBASE_SERVICE_ACCOUNT_PATH);admin.initializeApp({credential:admin.credential.cert(serviceAccount)}),console.log("Firebase Admin SDK initialized successfully.")}catch(error){console.error("Error initializing Firebase Admin SDK:",error.message),console.error("Ensure FIREBASE_SERVICE_ACCOUNT_PATH is correct and the file exists"),process.exit(1)}let octokit;try{octokit=new Octokit({authStrategy:createAppAuth,auth:{appId:GITHUB_APP_ID,privateKey:effectiveGitHubAppPrivateKey.replace(/\\n/g,"\n"),installationId:GITHUB_APP_INSTALLATION_ID}}),console.log("Octokit initialized successfully.")}catch(error){console.error("Error initializing Octokit:",error.message),console.error("Ensure GITHUB_APP_ID, GITHUB_APP_PRIVATE_KEY, and GITHUB_APP_INSTALLATION_ID are correct and have the necessary permissions."),process.exit(1)}const app=express();app.set("trust proxy",1);const apiLimiter=rateLimit({windowMs:9e5,max:20,standardHeaders:!0,legacyHeaders:!1,message:"Too many requests from this IP, please try again after 15 minutes"});let upload;try{const storage=multer.memoryStorage();upload=multer({storage:storage,limits:{fileSize:10485760}}),console.log("Multer initialized successfully.")}catch(error){console.error("Error setting up Multer:",error.message),process.exit(1)}console.log(`CORS: Allowing requests from origin: ${FRONTEND_ORIGIN}`);const corsOptions={origin:FRONTEND_ORIGIN,methods:["POST","OPTIONS"],allowedHeaders:["Content-Type","Authorization"],credentials:!0};app.use(cors(corsOptions));try{app.use(express.json()),console.log("JSON parsing middleware set up.")}catch(error){console.error("Error setting up JSON parsing middleware:",error.message),process.exit(1)}async function firebaseAuthMiddleware(req,res,next){const authHeader=req.headers.authorization;if(!authHeader||!authHeader.startsWith("Bearer "))return res.status(401).json({message:"Unauthorized: No token provided."});const idToken=authHeader.split("Bearer ")[1];try{const decodedToken=await admin.auth().verifyIdToken(idToken);if(decodedToken.aud!==FIREBASE_PROJECT_ID)return res.status(401).json({message:"Unauthorized: Invalid token (audience mismatch)."});const userRole=decodedToken.roles;if("admin"!==userRole&&"upload"!==userRole)return res.status(403).json({message:"Forbidden: Insufficient permissions."});req.user=decodedToken,next()}catch(error){return console.error("Error verifying Firebase ID token:",error),res.status(401).json({message:"Unauthorized: Invalid token.",error:error.message})}}try{app.get("/",((req,res)=>{console.log(`${(new Date).toISOString()} - Received GET request on /`),res.status(200).json({message:"Welcome to the Excelite API. Please upload files."})})),app.post("/",apiLimiter,firebaseAuthMiddleware,upload.fields([{name:"inventoryFile",maxCount:1},{name:"catalogFile",maxCount:1}]),(async(req,res)=>{console.log(`${(new Date).toISOString()} - Received POST file upload request on /`);const files=req.files,inventoryFile=files?.inventoryFile?.[0],catalogFile=files?.catalogFile?.[0];if(!inventoryFile&&!catalogFile)return res.status(400).json({message:"Bad Request: At least one file (inventoryFile or catalogFile) is required."});let tempInventoryFilePath="",tempCatalogFilePath="",processedInventory=!1,processedCatalog=!1;try{const{main:splitExcelBotMain}=await import("./splitExcel-bot.min.js"),githubConfig={appId:GITHUB_APP_ID,privateKey:effectiveGitHubAppPrivateKey,installationId:GITHUB_APP_INSTALLATION_ID,owner:GITHUB_OWNER,repo:GITHUB_REPO};if(fs.existsSync(SERVER_TEMP_DIR)||fs.mkdirSync(SERVER_TEMP_DIR,{recursive:!0}),inventoryFile){if(console.log(`Received inventory file: ${inventoryFile.originalname}`),!inventoryFile.originalname.endsWith(".xlsx"))return res.status(400).json({message:"Invalid inventory file type. Expected .xlsx"});const sanitizedInventoryFilename=sanitizeFilename(inventoryFile.originalname);tempInventoryFilePath=path.join(SERVER_TEMP_DIR,sanitizedInventoryFilename),fs.writeFileSync(tempInventoryFilePath,inventoryFile.buffer),console.log(`Inventory file temporarily saved to ${tempInventoryFilePath}`),await splitExcelBotMain(tempInventoryFilePath,"INVENTORY_FILE",githubConfig),console.log("Inventory file processed by splitExcel-bot."),processedInventory=!0}if(catalogFile){if(console.log(`Received catalog file: ${catalogFile.originalname}`),!catalogFile.originalname.endsWith(".xls"))return res.status(400).json({message:"Invalid catalog file type. Expected .xls"});const sanitizedCatalogFilename=sanitizeFilename(catalogFile.originalname);tempCatalogFilePath=path.join(SERVER_TEMP_DIR,sanitizedCatalogFilename),fs.writeFileSync(tempCatalogFilePath,catalogFile.buffer),console.log(`Catalog file temporarily saved to ${tempCatalogFilePath}`),await splitExcelBotMain(tempCatalogFilePath,"CATALOG_FILE",githubConfig),console.log("Catalog file processed by splitExcel-bot."),processedCatalog=!0}console.log("GitHub secrets updated for processed files via splitExcel-bot."),processedInventory&&processedCatalog&&inventoryFile&&catalogFile?(console.log("Verifying uploaded files against reconstructed chunks..."),await verifyUploadedFilesAgainstReconstructed(inventoryFile.originalname,catalogFile.originalname,NUM_CHUNKS,inventoryFile.buffer,catalogFile.buffer),console.log("Local file verification successful: Uploaded content matches reconstructed chunks.")):(processedInventory||processedCatalog)&&console.log("Skipping full file verification as only one file type was processed or uploaded."),console.log("Triggering GitHub Actions workflow..."),await triggerWorkflow(GITHUB_OWNER,GITHUB_REPO,"build-bot.yml","v2.x.x",octokit);let successMessage="";processedInventory&&processedCatalog?successMessage="Both inventory and catalog files processed, secrets updated, and site update triggered.":processedInventory?successMessage="Inventory file processed, secrets updated, and site update triggered.":processedCatalog&&(successMessage="Catalog file processed, secrets updated, and site update triggered."),res.status(200).json({message:successMessage})}catch(error){console.error("Error processing files or updating secrets:",error),error.status&&console.error("GitHub API Error Details:",error.response?.data),res.status(500).json({message:"Failed to process files or update secrets.",error:error.message})}finally{tempInventoryFilePath&&fs.existsSync(tempInventoryFilePath)&&(fs.unlinkSync(tempInventoryFilePath),console.log(`Cleaned up temporary inventory file: ${tempInventoryFilePath}`)),tempCatalogFilePath&&fs.existsSync(tempCatalogFilePath)&&(fs.unlinkSync(tempCatalogFilePath),console.log(`Cleaned up temporary catalog file: ${tempCatalogFilePath}`))}}))}catch(error){console.error("Error setting up API endpoint:",error.message),process.exit(1)}try{app.listen(PORT,(()=>{console.log(`Backend server listening on port ${PORT}`),console.log(`Accepting requests from origin: ${FRONTEND_ORIGIN}`)}))}catch(error){console.error("Error starting server:",error.message),process.exit(1)}async function triggerWorkflow(owner,repo,workflow_id,ref,appOctokit){try{await appOctokit.request("POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches",{owner:owner,repo:repo,workflow_id:workflow_id,ref:ref}),console.log(`Successfully triggered workflow: ${workflow_id}`)}catch(error){console.error(`Error triggering workflow ${workflow_id}:`,error)}}async function verifyUploadedFilesAgainstReconstructed(inventoryOriginalName,catalogOriginalName,numChunks,originalInventoryBuffer,originalCatalogBuffer){const botTempDir=path.join(__dirname,".temp");let inventorySuccess=!1,catalogSuccess=!1;try{console.log("\nüìä Verifying inventory file against its original upload...");const originalInventoryHash=crypto.createHash("sha256").update(originalInventoryBuffer).digest("hex");console.log(`üîç Original uploaded inventory file hash: ${originalInventoryHash}`),console.log(`üìä Original uploaded inventory size: ${originalInventoryBuffer.length} bytes`);const inventoryChunks=[];for(let i=0;i<numChunks;i++){const chunkPath=path.join(botTempDir,`INVENTORY_FILE_chunk_${i}`);if(!fs.existsSync(chunkPath))throw console.error(`‚ùå Error: Inventory chunk ${i} not found at ${chunkPath}`),new Error(`Missing inventory chunk for verification: INVENTORY_FILE_chunk_${i}`);{const data=fs.readFileSync(chunkPath);inventoryChunks.push(data),console.log(`‚úÖ Read inventory chunk ${i} (${data.length} bytes) from ${chunkPath}`)}}if(inventoryChunks.length!==numChunks)throw new Error(`Expected ${numChunks} inventory chunks for verification, but found ${inventoryChunks.length}`);const reconstructedInventoryBuffer=Buffer.concat(inventoryChunks);console.log(`‚úÖ Combined ${inventoryChunks.length} inventory chunks: ${reconstructedInventoryBuffer.length} bytes`);const reconstructedInventoryHash=crypto.createHash("sha256").update(reconstructedInventoryBuffer).digest("hex");if(console.log(`üîê Reconstructed inventory from chunks, hash: ${reconstructedInventoryHash}`),reconstructedInventoryHash!==originalInventoryHash)throw console.error("‚ùå Inventory file hash verification: MISMATCH (Uploaded !== Reconstructed) ‚úó"),console.log(`   Original Uploaded: ${originalInventoryHash}`),console.log(`   Reconstructed    : ${reconstructedInventoryHash}`),new Error("Inventory file hash mismatch: Original uploaded content does not match content reconstructed from bot's chunks.");console.log("‚úÖ Inventory file hash verification: MATCH (Uploaded === Reconstructed) ‚úì"),inventorySuccess=!0,console.log("\nüìö Verifying catalog file against its original upload...");const originalCatalogHash=crypto.createHash("sha256").update(originalCatalogBuffer).digest("hex");console.log(`üîç Original uploaded catalog file hash: ${originalCatalogHash}`),console.log(`üìä Original uploaded catalog size: ${originalCatalogBuffer.length} bytes`);const catalogChunks=[];for(let i=0;i<numChunks;i++){const chunkPath=path.join(botTempDir,`CATALOG_FILE_chunk_${i}`);if(!fs.existsSync(chunkPath))throw console.error(`‚ùå Error: Catalog chunk ${i} not found at ${chunkPath}`),new Error(`Missing catalog chunk for verification: CATALOG_FILE_chunk_${i}`);{const data=fs.readFileSync(chunkPath);catalogChunks.push(data),console.log(`‚úÖ Read catalog chunk ${i} (${data.length} bytes) from ${chunkPath}`)}}if(catalogChunks.length!==numChunks)throw new Error(`Expected ${numChunks} catalog chunks for verification, but found ${catalogChunks.length}`);const reconstructedCatalogBuffer=Buffer.concat(catalogChunks);console.log(`‚úÖ Combined ${catalogChunks.length} catalog chunks: ${reconstructedCatalogBuffer.length} bytes`);const reconstructedCatalogHash=crypto.createHash("sha256").update(reconstructedCatalogBuffer).digest("hex");if(console.log(`üîê Reconstructed catalog from chunks, hash: ${reconstructedCatalogHash}`),reconstructedCatalogHash!==originalCatalogHash)throw console.error("‚ùå Catalog file hash verification: MISMATCH (Uploaded !== Reconstructed) ‚úó"),console.log(`   Original Uploaded: ${originalCatalogHash}`),console.log(`   Reconstructed    : ${reconstructedCatalogHash}`),new Error("Catalog file hash mismatch: Original uploaded content does not match content reconstructed from bot's chunks.");if(console.log("‚úÖ Catalog file hash verification: MATCH (Uploaded === Reconstructed) ‚úì"),catalogSuccess=!0,console.log("\nüìã Verification summary (Uploaded vs. Reconstructed from bot's .temp chunks):"),console.log("   Inventory file: "+(inventorySuccess?"‚úÖ SUCCESS":"‚ùå FAILED")),console.log("   Catalog file: "+(catalogSuccess?"‚úÖ SUCCESS":"‚ùå FAILED")),inventorySuccess&&catalogSuccess)return console.log("\n‚úÖ All uploaded files successfully verified against reconstructed versions from bot's chunks!"),!0;throw new Error("One or more files failed verification against reconstructed versions.")}catch(error){throw console.error("‚ùå Error during local file verification (Uploaded vs. Reconstructed from bot's .temp chunks):",error.message),error}}