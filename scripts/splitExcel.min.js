import{readFileSync,writeFileSync,statSync,mkdirSync,rmSync,existsSync}from"fs";import sodium from"libsodium-wrappers";import{Octokit}from"@octokit/rest";import{createHash}from"crypto";import{config}from"dotenv";config();const{GITHUB_TOKEN:GITHUB_TOKEN,GITHUB_OWNER:GITHUB_OWNER,GITHUB_REPO:GITHUB_REPO,VITE_INVENTORY_FILE:VITE_INVENTORY_FILE,VITE_CATALOG_FILE:VITE_CATALOG_FILE}=process.env,octokit=new Octokit({auth:GITHUB_TOKEN}),NUM_CHUNKS=6,TEMP_DIR="./.temp";async function processFile(filePath,secretPrefix){try{console.log(`\nüìÑ Processing file: ${filePath}`);const originalSize=statSync(filePath).size;if(0===originalSize)throw new Error(`‚ùå Error: ${filePath} is empty`);const fileBuffer=readFileSync(filePath),chunkSize=Math.ceil(fileBuffer.length/NUM_CHUNKS),base64Chunks=[],originalHash=createHash("sha256").update(fileBuffer).digest("hex");console.log(`üîí Original file hash: ${originalHash}`),console.log(`üìä Original file size: ${originalSize} bytes`);const chunks=[];let totalSize=0;for(let i=0;i<NUM_CHUNKS;i++){const start=i*chunkSize,end=Math.min(start+chunkSize,fileBuffer.length),chunk=fileBuffer.subarray(start,end),chunkPath=`${TEMP_DIR}/${secretPrefix}_chunk_${i}`;writeFileSync(chunkPath,chunk);const writtenSize=statSync(chunkPath).size;chunks.push(chunk),totalSize+=chunk.length,console.log(`üì¶ Chunk ${i+1}:`),console.log(`   Size: ${chunk.length} bytes`),console.log(`   Written size: ${writtenSize} bytes`);const secretName=`${secretPrefix}_CHUNK_${i+1}`,secretValue=Buffer.from(chunk).toString("base64");base64Chunks.push(secretValue);const decodedSize=Buffer.from(secretValue,"base64").length;if(decodedSize!==chunk.length)throw new Error(`Base64 validation failed for chunk ${i+1}! Original: ${chunk.length}, Decoded: ${decodedSize}`);console.log(`   Base64 length: ${secretValue.length}`),console.log("   Decoded size matches: ‚úÖ"),await updateGithubSecret(secretName,secretValue)}const decodedChunks=base64Chunks.map((str=>Buffer.from(str,"base64"))),combinedBuffer=Buffer.concat(decodedChunks),finalHash=createHash("sha256").update(combinedBuffer).digest("hex");if(console.log("\nüîç Final validation:"),console.log(`   Original size: ${originalSize} bytes`),console.log(`   Final size: ${combinedBuffer.length} bytes`),console.log(`   Original hash: ${originalHash}`),console.log(`   Final hash: ${finalHash}`),console.log("   Hashes match: "+(originalHash===finalHash?"‚úÖ":"‚ùå")),totalSize!==originalSize)throw new Error(`Size mismatch after splitting! Original: ${originalSize}, Chunks total: ${totalSize}`);return console.log(`‚úÖ Successfully split file into ${NUM_CHUNKS} chunks`),console.log("üîç Validations passed:"),console.log(`   - Original size: ${originalSize} bytes`),console.log(`   - Total chunks size: ${totalSize} bytes`),console.log("   - All chunks properly base64 encoded"),!0}catch(error){return console.error(`‚ùå Error processing ${filePath}:`,error),!1}}async function updateGithubSecret(secretName,secretValue){try{const{data:publicKey}=await octokit.actions.getRepoPublicKey({owner:GITHUB_OWNER,repo:GITHUB_REPO}),secretBytes=Buffer.from(secretValue),keyBytes=Buffer.from(publicKey.key,"base64");await sodium.ready;const encryptedBytes=sodium.crypto_box_seal(secretBytes,keyBytes),encrypted=Buffer.from(encryptedBytes).toString("base64");await octokit.actions.createOrUpdateRepoSecret({owner:GITHUB_OWNER,repo:GITHUB_REPO,secret_name:secretName,encrypted_value:encrypted,key_id:publicKey.key_id}),console.log(`‚úÖ Updated secret: ${secretName}`)}catch(error){throw console.error(`‚ùå Failed to update secret ${secretName}:`,error),error}}async function main(){const missingVars=["GITHUB_TOKEN","GITHUB_OWNER","GITHUB_REPO","VITE_INVENTORY_FILE","VITE_CATALOG_FILE"].filter((varName=>!process.env[varName]));missingVars.length>0&&(console.error("‚ùå Missing required environment variables:",missingVars.join(", ")),process.exit(1));try{mkdirSync(TEMP_DIR,{recursive:!0});const inventoryFilePath=`./public/assets/${VITE_INVENTORY_FILE}`,inventorySuccess=await processFile(inventoryFilePath,"INVENTORY_FILE"),catalogFilePath=`./public/assets/${VITE_CATALOG_FILE}`,catalogSuccess=await processFile(catalogFilePath,"CATALOG_FILE");if(inventorySuccess&&catalogSuccess){console.log("\nüéâ All files processed successfully!"),console.log("üîë All secrets updated on GitHub"),console.log("üîç Validating the combined files");if(!testChunks())throw new Error("‚ùå Combined files do not match the original files");console.log("‚úÖ All validations passed")}else console.error("\n‚ùå One or more files failed to process"),process.exit(1)}catch(error){console.error("‚ùå Error:",error),process.exit(1)}finally{try{console.log("\nüßπ Cleaning up..."),rmSync(TEMP_DIR,{recursive:!0,force:!0}),console.log("üßπ Cleaned up temporary files")}catch(cleanupError){console.error("‚ùå Failed to clean up temp directory:",cleanupError)}}}function testChunks(){const{VITE_INVENTORY_FILE:VITE_INVENTORY_FILE,VITE_CATALOG_FILE:VITE_CATALOG_FILE}=process.env;VITE_INVENTORY_FILE||(console.error("‚ùå Error: VITE_INVENTORY_FILE environment variable is not set"),process.exit(1)),VITE_CATALOG_FILE||(console.error("‚ùå Error: VITE_CATALOG_FILE environment variable is not set"),process.exit(1)),existsSync("./public")||mkdirSync("./public",{recursive:!0}),existsSync("./public/assets")||mkdirSync("./public/assets",{recursive:!0});let inventorySuccess=!1,catalogSuccess=!1;try{const inventoryFilePath=`./public/assets/${VITE_INVENTORY_FILE}`;let originalInventoryHash=null;if(existsSync(inventoryFilePath)){const originalInventory=readFileSync(inventoryFilePath);originalInventoryHash=createHash("sha256").update(originalInventory).digest("hex"),console.log(`üîç Original inventory file hash: ${originalInventoryHash}`),console.log(`üìä Original inventory size: ${originalInventory.length} bytes`),writeFileSync(`${inventoryFilePath}.bak`,originalInventory)}const catalogFilePath=`./public/assets/${VITE_CATALOG_FILE}`;let originalCatalogHash=null;if(existsSync(catalogFilePath)){const originalCatalog=readFileSync(catalogFilePath);originalCatalogHash=createHash("sha256").update(originalCatalog).digest("hex"),console.log(`üîç Original catalog file hash: ${originalCatalogHash}`),console.log(`üìä Original catalog size: ${originalCatalog.length} bytes`),writeFileSync(`${catalogFilePath}.bak`,originalCatalog)}console.log("\nüìä Processing inventory file...");const inventoryChunks=[];for(let i=0;i<6;i++){const chunkPath=`./.temp/INVENTORY_FILE_chunk_${i}`;if(!existsSync(chunkPath))throw console.error(`‚ö†Ô∏è Warning: Inventory chunk ${i} not found at ${chunkPath}`),new Error("Missing inventory chunks");{const data=readFileSync(chunkPath);inventoryChunks.push(data),console.log(`‚úÖ Read inventory chunk ${i}: ${data.length} bytes`)}}const combinedInventory=Buffer.concat(inventoryChunks);console.log(`‚úÖ Combined ${inventoryChunks.length} inventory chunks: ${combinedInventory.length} bytes`);const inventoryHash=createHash("sha256").update(combinedInventory).digest("hex");console.log(`üîê Reconstructed inventory file hash: ${inventoryHash}`),writeFileSync(inventoryFilePath,combinedInventory),console.log(`‚úÖ Wrote inventory file: ${combinedInventory.length} bytes`),originalInventoryHash&&inventoryHash===originalInventoryHash?(console.log("‚úÖ Inventory file hash verification: MATCH ‚úì"),inventorySuccess=!0):originalInventoryHash?(console.error("‚ùå Inventory file hash verification: MISMATCH ‚úó"),console.log(`   Original: ${originalInventoryHash}`),console.log(`   Reconstructed: ${inventoryHash}`)):(console.log("‚ÑπÔ∏è No original inventory file to compare hash with"),inventorySuccess=!0),console.log("\nüìö Processing catalog file...");const catalogChunks=[];for(let i=0;i<6;i++){const chunkPath=`./.temp/CATALOG_FILE_chunk_${i}`;if(!existsSync(chunkPath))throw console.error(`‚ö†Ô∏è Warning: Catalog chunk ${i} not found at ${chunkPath}`),new Error("Missing catalog chunks");{const data=readFileSync(chunkPath);catalogChunks.push(data),console.log(`‚úÖ Read catalog chunk ${i}: ${data.length} bytes`)}}const combinedCatalog=Buffer.concat(catalogChunks);console.log(`‚úÖ Combined ${catalogChunks.length} catalog chunks: ${combinedCatalog.length} bytes`);const catalogHash=createHash("sha256").update(combinedCatalog).digest("hex");return console.log(`üîê Reconstructed catalog file hash: ${catalogHash}`),writeFileSync(catalogFilePath,combinedCatalog),console.log(`‚úÖ Wrote catalog file: ${combinedCatalog.length} bytes`),originalCatalogHash&&catalogHash===originalCatalogHash?(console.log("‚úÖ Catalog file hash verification: MATCH ‚úì"),catalogSuccess=!0):originalCatalogHash?(console.error("‚ùå Catalog file hash verification: MISMATCH ‚úó"),console.log(`   Original: ${originalCatalogHash}`),console.log(`   Reconstructed: ${catalogHash}`)):(console.log("‚ÑπÔ∏è No original catalog file to compare hash with"),catalogSuccess=!0),console.log("\nüìã Verification summary:"),console.log("   Inventory file: "+(inventorySuccess?"‚úÖ SUCCESS":"‚ùå FAILED")),console.log("   Catalog file: "+(catalogSuccess?"‚úÖ SUCCESS":"‚ùå FAILED")),inventorySuccess&&catalogSuccess?(console.log("\n‚úÖ All files processed and verified successfully!"),!0):(console.error("\n‚ùå One or more files failed verification!"),!1)}catch(error){console.error("‚ùå Error:",error.message),process.exit(1)}}main();